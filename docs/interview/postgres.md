## postgres集群方案  
* postgres 主从  
  在小规模集群  业务数据量千万左右或者以下  一主N从基本够用 合理设计分区表 而且需要业务系统的配合来做读写分离 和负载均衡   
  
* pgpool+postgres    
  在对可用性 性能有比较高的要求的时候     
  可以利用pgpool来管理postgres 主从集群 来达到主备和读写分离、负载均衡   
  但是这种方式 需要部署pgpool高可用 多了三台设备 只适合大规模使用postgres场景下       


## postgres和mysql比较     
* postgres   
  多进程架构   
  支持事务、存储过程(本地缓存执行计划)   
  pg在极限负载下较为稳定       
  在崩溃、断电 情况下能够很好的保证数据完整新         
  超大内存下 pg对内存使用 没有mysql的innodb引擎好   
  pg数据同步可以做到同步、异步、半同步复制 属于物理复制   
  pgsql 9.2之后支持从带从    
  pgsql sql编程和支持多种脚本语言脚本 如python   
  分区使用继承方式实现数据分区    
  单机千万级别数据 可以抗住    


* mysql    
  多线程架构   
  支持事务、存储过程   
  极限负载回出现性能下滑    
  在innodb引擎崩溃、断电场景下可能会丢失数据   
  mysql使用binlog复制  属于逻辑复制   
  单机百万级别数据 可以抗住   
  


## postgres sql优化思路 
>explain 查看执行计划    
> 参考文档:https://blog.xujiuming.com/ming/2c157461.html
  
postgres的sql优化 一般来说做好常规优化 和索引  问题不是很大   
如果要分析sql的瓶颈 可以利用explain来查看执行计划   
看看 join模式 和扫描方式  是不是不符合预期    
一般出现seq scan 之类的就是可以优化的点    
一般就是添加添加索引  或者改改过滤条件减少join的数据量   基本上够用    
还不够 就要考虑使用数据分区或者直接分表分库来处理     
因为编写比较极限的sql  意义并不大  增加难度 场景适应性低  一旦改变需求 写的好的sql 也得作废     

  
  

## 数据库事务隔离级别
>参考文档:https://www.cnblogs.com/dongyaotou/p/13294577.html 

1. 读未提交 READ UNCOMMITTED
2. 读已提交 READ COMMITTED
3. 重复读 REPEATABLE READ
4. 串行  SERIALIZABLE 

1. 脏读:一个事务读取了另一个未提交事务写入的数据
2. 不可重复度: 一个事务重新读取之前读取过的数据  发现已经改变  
3. 幻读:一个事务开启后 需要根据根据已存在的字段去更新 回执行查询返回符合条件的数据 这个时候因为其他事务提交发生了改变 会导致当前事务无法进行 导致逻辑失败

|隔离级别|脏读|不可重复读|幻读|
|------|---|--------|---|
|读未提交|√|√|√|
|读已提交|×|√|√|
|重复读|×|×|√|
|串行|×|×|×|

:::tips
postgres 默认隔离级别是 \[读已提交]  不会出现脏读  但是回出现不可重复读和幻读 
:::
